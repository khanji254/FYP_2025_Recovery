\section{Research Design and Methodology}
\label{sec:methodology}

This study will adopt an experimental and design-based research approach. The research will involve the modification and improvement of an existing image-based coffee berry sorting machine through systematic redesign of its mechanical, electrical, and software subsystems. A functional prototype will be developed and evaluated to determine improvements in sorting accuracy, processing speed, and system reliability. The research design will be iterative, where system performance will be evaluated at each stage, and necessary refinements will be implemented to address identified limitations such as motion blur, processing delays, and ejection timing inaccuracies observed in the previous model.

\subsection{System Overview}

The proposed coffee berry sorting machine will consist of three main modules:

\begin{itemize}
    \item \textbf{Mechanical Module} -- Responsible for controlled berry feeding, alignment, and physical support
    \item \textbf{Electrical and Electronic Module} -- Responsible for sensing, actuation, power distribution, and processing
    \item \textbf{Software Module} -- Responsible for image acquisition, processing, classification, tracking, and ejection control
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{Figures/system_architecture.pdf}
\caption{Overall system architecture of the improved coffee berry sorting machine}
\label{fig:system_architecture}
\end{figure}

Each module will be designed to work in synchronization to enable real-time detection, classification, and rejection of unwanted coffee berries.

\subsection{Mechanical Module Design}

The mechanical module will be designed to ensure consistent berry flow, minimal vibration-induced image distortion, accurate alignment, and precise ejection positioning.

\subsubsection{Hopper}

The hopper will be used to store harvested coffee berries before sorting. It will be designed with sloped walls to allow gravity-assisted flow while preventing clogging and bridging of berries.

\textbf{Material Selection:} Mild steel sheet or food-grade aluminium will be used due to: structural strength, ease of fabrication, resistance to wear, and suitability for agricultural products. The hopper will feed berries uniformly onto the vibrating feeder.

\subsubsection{Linear Vibrating Feeder}

A linear vibrating feeder will be employed to regulate the flow rate of coffee berries and prevent overlapping during image capture. Controlled vibration will ensure berries are spread into a near-single-file arrangement.

\textbf{Justification:} Reduces berry overlap, improves image clarity, minimizes motion blur, and enhances object tracking accuracy.

\textbf{Material Selection:} Stainless steel or aluminium tray to reduce corrosion and contamination. Rubber vibration isolators to reduce transmission of vibration to the camera holder.

\subsubsection{Chute}

The chute will guide berries from the feeder to the imaging zone while maintaining alignment and spacing.

\textbf{Design Considerations:} Inclination angle optimized for gravity flow, smooth surface finish to reduce friction, fixed berry trajectory for predictable motion.

\textbf{Material Selection:} Acrylic or aluminium sheet chosen for smoothness, light weight, and ease of modification.

\subsubsection{Camera Holder}

The camera holder will support the Raspberry Pi camera directly above the imaging zone. It will be mechanically isolated from vibrations originating from the feeder.

\textbf{Design Improvements:} Use of rubber dampers to reduce vibration transmission, rigid frame mounting to maintain fixed focal distance, adjustable height mechanism for calibration.

\textbf{Material Selection:} Aluminium profile or 3D-printed ABS selected for rigidity and lightweight properties.

\subsubsection{Ejection Holder}

The ejection holder will house the air ejectors responsible for rejecting unwanted berries.

\textbf{Design Considerations:} Precise alignment with berry trajectory, fixed distance from detection zone to allow accurate ejection scheduling, modular design for easy adjustment.

\textbf{Material Selection:} Aluminium brackets resistant to vibration and compressed air forces.

\subsubsection{Frame Structure}

The frame will support all mechanical and electrical components.

\textbf{Material Selection:} Mild steel angle bars or aluminium extrusion selected for strength, stability, and ease of assembly.
\subsection{Proposed Electrical and Control Module}

The proposed electrical and control module will be designed to support high-speed image acquisition, real-time processing, and precise actuation required for accurate coffee berry sorting. To address the processing bottlenecks identified in the previous system, a co-processing architecture will be introduced.

\subsubsection{Central Processing and Co-Processing Architecture}

The system will employ a Raspberry Pi 3 as the main processing unit responsible for computationally intensive tasks. The Raspberry Pi will handle image acquisition, image processing, classification using machine learning models, and object tracking across frames. These operations require significant computational resources and are best suited to the Raspberry Pi's processing capabilities.

To improve system responsiveness and reduce latency in real-time control operations, an ESP32 microcontroller will be introduced as a co-processing unit. This secondary processor will handle motor control for the vibrating feeder, timing calculations for ejection scheduling, direct interfacing with solenoid actuators, and sensor signal conditioning. By offloading these real-time control tasks from the Raspberry Pi, the system achieves better parallel processing and enhanced real-time performance.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{Figures/coprocessing_architecture.pdf}
\caption{Co-processing architecture showing task distribution: Raspberry Pi handles image processing, classification, and tracking; ESP32 handles motor control, actuator interfacing, and timing}
\label{fig:coprocessing_architecture}
\end{figure}

The division of tasks will be implemented as follows: The Raspberry Pi will execute all image processing operations including pre-processing, feature extraction, CNN-based classification, and multi-frame object tracking. The ESP32 co-processor will manage motor speed control for the vibrating feeder, calculate precise timing for ejection based on berry position data received from the Raspberry Pi, directly trigger solenoid actuators, and condition sensor signals before transmission.

Communication between the Raspberry Pi and the ESP32 will be achieved through high-speed UART serial communication, ensuring minimal data transfer delay. The Raspberry Pi will transmit classification results and position data to the ESP32, which will then execute the corresponding actuation commands.

\subsubsection{Image Acquisition System}

A Raspberry Pi Camera Module will be mounted above the chute using a rigid camera holder to capture high-resolution images of coffee berries in motion. The camera will operate at an optimized frame rate to balance image clarity and processing speed while minimizing motion blur.

Controlled LED lighting modules will be installed around the imaging zone to provide uniform illumination, reduce shadows, and ensure consistent image quality regardless of ambient lighting conditions.

\subsubsection{Air Ejection and Actuation System}

The berry rejection mechanism will consist of: high-speed air ejectors (solenoid-controlled air nozzles) positioned along the chute, and a compressed air supply system, including a compact air compressor and pressure regulation unit.

The Raspberry Pi will perform real-time classification and tracking of berries, computing their positions and velocities. This information will be transmitted to the ESP32, which will calculate precise ejection timing and directly trigger the solenoid actuators. This distributed approach ensures accurate rejection of defective or unripe berries without affecting accepted berries.

\subsubsection{Motor Control and Power Supply}

Electric motors used in the linear vibrating feeder will be selected based on vibration frequency requirements, durability, and power efficiency. The ESP32 will control motor drivers to enable precise adjustment of feed rate, ensuring optimal berry spacing for image capture.

The system will utilize: a regulated 5V DC supply for logic-level electronics (Raspberry Pi, ESP32, camera), and a 12V DC supply for actuators, air solenoids, and motors.

Power isolation and protection mechanisms will be incorporated to prevent electrical noise from affecting sensitive processing units.

\subsection{Software Architecture and Control Logic}

The software system will be modular and executed in stages as outlined below:

\subsubsection{System Startup}

Upon power-up, the Raspberry Pi will initialize system peripherals, establish UART communication with the ESP32, and perform system diagnostics.

\subsubsection{Image Acquisition and Processing}

The Raspberry Pi Camera Module will capture images of berries in motion. Captured images will undergo pre-processing on the Raspberry Pi, including grayscale conversion, noise filtering, normalization, and contrast enhancement.

\subsubsection{Object Detection and Classification}

Coffee berries will be detected using contour-based methods executed on the Raspberry Pi. The classification system will employ a binary classifier (ripe vs. unripe) using a lightweight CNN model optimized with TensorFlow Lite, running on the Raspberry Pi.

\subsubsection{Object Tracking}

The Raspberry Pi will track detected berries across successive frames to determine velocity and trajectory. Tracking data will be used to compute berry positions and predict ejection points.

\subsubsection{Control and Ejection}

Based on classification and tracking results, the Raspberry Pi will transmit berry position and classification data to the ESP32 via UART. The ESP32 will calculate optimal actuation timing and trigger the appropriate air ejectors to reject unwanted berries.

The binary classification model (ripe vs. unripe) will be trained using MobileNetV2 architecture, optimized with TensorFlow Lite for efficient deployment on the Raspberry Pi. The model will be trained with data augmentation techniques and quantized to maintain classification accuracy above 90\% while minimizing inference time.

\subsubsection{System Flow Control}

The Raspberry Pi will supervise the entire operation, adjusting system parameters, handling exceptions, and logging performance metrics. Figure~\ref{fig:control_flow} shows the overall control flow, while Figure~\ref{fig:processing_flow} illustrates the image processing pipeline.

\begin{figure}[h]
\centering
\includegraphics[width=0.65\textwidth]{Figures/control_flow.pdf}
\caption{System control flow showing task distribution between Raspberry Pi 3 (image processing, classification, tracking) and ESP32 (motor control, timing, actuation)}
\label{fig:control_flow}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.55\textwidth]{Figures/processing_flow.pdf}
\caption{Image processing pipeline executed on Raspberry Pi 3, showing stages from raw image capture through pre-processing, detection, classification (CNN), and tracking to final output transmitted to ESP32}
\label{fig:processing_flow}
\end{figure}
